{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai\n",
      "  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/harukary/workspace/gpt_recipe_app/.venv/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /home/harukary/workspace/gpt_recipe_app/.venv/lib/python3.9/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/harukary/workspace/gpt_recipe_app/.venv/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/harukary/workspace/gpt_recipe_app/.venv/lib/python3.9/site-packages (from requests>=2.20->openai) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harukary/workspace/gpt_recipe_app/.venv/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/harukary/workspace/gpt_recipe_app/.venv/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/harukary/workspace/gpt_recipe_app/.venv/lib/python3.9/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = open('../open_ai.key','r').read()\n",
    "# print(openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = openai_key\n",
    "def completion(new_message_text:str, settings_text:str = '', past_messages:list = []):\n",
    "    \"\"\"\n",
    "    This function generates a response message using OpenAI's GPT-3 model by taking in a new message text, \n",
    "    optional settings text and a list of past messages as inputs.\n",
    "\n",
    "    Args:\n",
    "    new_message_text (str): The new message text which the model will use to generate a response message.\n",
    "    settings_text (str, optional): The optional settings text that will be added as a system message to the past_messages list. Defaults to ''.\n",
    "    past_messages (list, optional): The optional list of past messages that the model will use to generate a response message. Defaults to [].\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the response message text and the updated list of past messages after appending the new and response messages.\n",
    "    \"\"\"\n",
    "    if len(past_messages) == 0 and len(settings_text) != 0:\n",
    "        system = {\"role\": \"system\", \"content\": settings_text}\n",
    "        past_messages.append(system)\n",
    "    new_message = {\"role\": \"user\", \"content\": new_message_text}\n",
    "    past_messages.append(new_message)\n",
    "\n",
    "    result = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=past_messages\n",
    "    )\n",
    "    response_message = {\"role\": \"assistant\", \"content\": result.choices[0].message.content}\n",
    "    past_messages.append(response_message)\n",
    "    response_message_text = result.choices[0].message.content\n",
    "    return response_message_text, past_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_settings = \"\"\"あなたは料理研究家です。質問に対して、食材や調理法、レシピの例を用いて回答してください。\n",
    "では、会話を開始します。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message, messages = completion(\"こんにちは\", system_settings, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、どのようなお悩みでしょうか？私は料理に関することなら何でもお答えできます。\n",
      "----------\n",
      "[{'role': 'system', 'content': 'あなたは料理研究家です。質問に対して、食材や調理法、レシピの例を用いて回答してください。\\nでは、会話を開始します。\\n'}, {'role': 'user', 'content': 'こんにちは'}, {'role': 'assistant', 'content': 'こんにちは、どのようなお悩みでしょうか？私は料理に関することなら何でもお答えできます。'}]\n"
     ]
    }
   ],
   "source": [
    "print(new_message)\n",
    "print('-'*10)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message2, messages2 = completion(\"さつまいもを使ったレシピの例と、栄養成分を教えてください。\", system_settings, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "さつまいもを使ったレシピとしては、甘く煮たり、焼いたりするのが一般的ですが、今回はピューレ状にして使うレシピをご紹介します。\n",
      "\n",
      "【さつまいものスープ】\n",
      "\n",
      "【材料】\n",
      "・さつまいも 2個\n",
      "・水 500ml\n",
      "・顆粒ダシ 小さじ1\n",
      "・バター 30g\n",
      "・生クリーム 50ml\n",
      "・塩、胡椒 適量\n",
      "\n",
      "【作り方】\n",
      "1. さつまいもは皮をむき、一口サイズに切って鍋に入れます。\n",
      "2. 水と顆粒ダシを加え、さつまいもが柔らかくなるまで煮ます。\n",
      "3. 火を止め、バターを加えてさつまいもを潰します。（マッシャーがあると便利です）\n",
      "4. 生クリームを加え、ソースパンで火を通して、塩と胡椒で味を整えます。\n",
      "5. 器に盛り付け、お好みでパセリやチーズをトッピングして完成です。\n",
      "\n",
      "このスープは、さつまいもに含まれるビタミンC、食物繊維、カリウムなどの栄養素が豊富に含まれています。特に、カリウムは体内の余分な塩分を排出してくれる作用があります。また、生クリームは油脂分が多いため、摂取量に注意が必要です。\n",
      "\n",
      "ぜひお試しください！\n"
     ]
    }
   ],
   "source": [
    "print(new_message2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a196dbc33342f67c01613a745ffdb34d35e1de6e0c43cc905192f4a5259ea38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
