{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = open('../open_ai.key','r').read()\n",
    "import os; os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.com/npaka/n/n716dfd26094d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI,OpenAIChat\n",
    "# OpenAIのLLMの生成\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2)\n",
    "# llm = OpenAIChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ネコの鳴き声は「ニャー」と言われることが多いですが、実際には様々な鳴き声を出しています。例えば、「モー」や「ミャウ」、「ウー」などがあります。\n"
     ]
    }
   ],
   "source": [
    "# LLMの呼び出し\n",
    "result = llm(\"ネコの鳴き声は？\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMResult(generations=[[Generation(text='\\n\\n猫の鳴き声は「ニャー」という音です。', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\n猫の鳴き声は「ニャー」という音です。', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nカラスの鳴き声は「カーカー」という鳴き声です。', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nカラスの鳴き声は「カーカー」です。', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 129, 'prompt_tokens': 26, 'completion_tokens': 103}})\n"
     ]
    }
   ],
   "source": [
    "# 高度なLLMの呼び出し\n",
    "result = llm.generate([\"猫の鳴き声は？\", \"カラスの鳴き声は？\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response0: \n",
      "\n",
      "猫の鳴き声は「ニャー」という音です。\n",
      "response1: \n",
      "\n",
      "カラスの鳴き声は「カーカー」という鳴き声です。\n",
      "llm_output: {'token_usage': {'total_tokens': 129, 'prompt_tokens': 26, 'completion_tokens': 103}}\n"
     ]
    }
   ],
   "source": [
    "# 出力テキスト\n",
    "print(\"response0:\", result.generations[0][0].text)\n",
    "print(\"response1:\", result.generations[1][0].text)\n",
    "\n",
    "# 使用したトークン数\n",
    "print(\"llm_output:\", result.llm_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMのシリアライズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "# LLMファイルの読み込み\n",
    "llm = load_llm(\"data/my_llm.json\")\n",
    "\n",
    "# LLMファイルの書き込み\n",
    "llm.save(\"my_llm.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMのキャッシュ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インメモリー\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# インメモリキャッシュの準備\n",
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.17 ms, sys: 69 µs, total: 4.24 ms\n",
      "Wall time: 1.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n私は人工知能エージェントであり、色を好むことはできません。'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(\"好きな色は？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 µs, sys: 12 µs, total: 33 µs\n",
      "Wall time: 35.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n私は人工知能エージェントであり、色を好むことはできません。'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(\"好きな色は？\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "# SQLiteキャッシュの準備\n",
    "langchain.llm_cache = SQLiteCache(database_path=\"data/langchain.db\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カスタムLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのインポート\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Mapping, Any\n",
    "\n",
    "# カスタムLLMの定義\n",
    "class CustomLLM(LLM):\n",
    "    n: int\n",
    "\n",
    "    # LLM種別を返す\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    # プロンプトとストップワードを受け取り応答を返す\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        return prompt[:self.n]  # 入力の最初のN文字を返す\n",
    "\n",
    "    # IDパラメータの辞書を返す\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"n\": self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'あいうえおかきくけこ'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# カスタムLLMの利用\n",
    "llm = CustomLLM(n=10)\n",
    "llm(\"あいうえおかきくけこさしすせそ\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.com/npaka/n/n97aac2da03f4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プロンプトの機能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "かっこいい動物といえば？\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 複数の入力変数を持つプロンプトテンプレートの準備\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"{adjective}{content}といえば？\"\n",
    ")\n",
    "print(multiple_input_prompt.format(adjective=\"かっこいい\", content=\"動物\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q: foo\n",
      "A: bar\n",
      "\n",
      "Q: 1\n",
      "A: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# テンプレートの準備 (jinja2)\n",
    "template = \"\"\"\n",
    "{% for item in items %}\n",
    "Q: {{ item.question }}\n",
    "A: {{ item.answer }}\n",
    "{% endfor %}\n",
    "\"\"\"\n",
    "\n",
    "# 入力変数の準備\n",
    "items=[\n",
    "    {\"question\": \"foo\", \"answer\": \"bar\"},\n",
    "    {\"question\": \"1\", \"answer\": \"2\"}\n",
    "]\n",
    "\n",
    "# jinja2を使ったプロンプトテンプレートの準備\n",
    "jinja2_prompt = PromptTemplate(\n",
    "    input_variables=[\"items\"],\n",
    "    template=template,\n",
    "    template_format=\"jinja2\"\n",
    ")\n",
    "print(jinja2_prompt.format(items=items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての入力の反意語を与えてください\n",
      "\n",
      "入力: 明るい\n",
      "出力: 暗い\n",
      "\n",
      "入力: おもしろい\n",
      "出力: つまらない\n",
      "\n",
      "入力: 大きい\n",
      "出力:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "# 例の準備\n",
    "examples = [\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"おもしろい\", \"output\": \"つまらない\"},\n",
    "]\n",
    "\n",
    "# 例のプロンプト\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "# FewShotPromptTemplateの準備\n",
    "prompt_from_string_examples = FewShotPromptTemplate(\n",
    "    examples=examples, # 例\n",
    "    example_prompt=example_prompt,  # 例のフォーマット\n",
    "    prefix=\"すべての入力の反意語を与えてください\",  # プレフィックス\n",
    "    suffix=\"入力: {adjective}\\n出力:\",  # サフィックス\n",
    "    input_variables=[\"adjective\"],  # 入力変数\n",
    "    example_separator=\"\\n\\n\"  # プレフィックスと例とサフィックスを結合する文字\n",
    "\n",
    ")\n",
    "print(prompt_from_string_examples.format(adjective=\"大きい\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての入力の反意語を与えてください\n",
      "\n",
      "入力: 明るい\n",
      "出力: 暗い\n",
      "\n",
      "入力: おもしろい\n",
      "出力: つまらない\n",
      "\n",
      "入力: 大きい\n",
      "出力:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "# 例の準備\n",
    "examples = [\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"おもしろい\", \"output\": \"つまらない\"},\n",
    "    {\"input\": \"エネルギッシュ\", \"output\": \"無気力\"},\n",
    "    {\"input\": \"高い\", \"output\": \"低い\"},\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"早い\", \"output\": \"遅い\"},\n",
    "]\n",
    "\n",
    "# 例のプロンプト\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "# LengthBasedExampleSelectorの準備\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,  # 例\n",
    "    example_prompt=example_prompt,  # 例のフォーマット\n",
    "    max_length=10,  # 最大長\n",
    ")\n",
    "\n",
    "# FewShotPromptTemplateの準備\n",
    "prompt_from_string_examples = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # ExampleSelector\n",
    "    example_prompt=example_prompt,  # 例のフォーマット\n",
    "    prefix=\"すべての入力の反意語を与えてください\",  # プレフィックス\n",
    "    suffix=\"入力: {adjective}\\n出力:\",  # サフィックス\n",
    "    input_variables=[\"adjective\"],  # 入力変数\n",
    "    example_separator=\"\\n\\n\"  # プレフィックスと例とサフィックスを結合する文字\n",
    "\n",
    ")\n",
    "print(prompt_from_string_examples.format(adjective=\"大きい\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての入力の反意語を与えてください\n",
      "\n",
      "入力: 高い\n",
      "出力: 低い\n",
      "\n",
      "入力: 大きい\n",
      "出力:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "# 例の準備\n",
    "examples = [\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"おもしろい\", \"output\": \"つまらない\"},\n",
    "    {\"input\": \"エネルギッシュ\", \"output\": \"無気力\"},\n",
    "    {\"input\": \"高い\", \"output\": \"低い\"},\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"早い\", \"output\": \"遅い\"},\n",
    "]\n",
    "\n",
    "# 例のプロンプト\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "# SemanticSimilarityExampleSelectorの準備\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,  # 例\n",
    "    OpenAIEmbeddings(),  # 埋め込み生成のためのクラス\n",
    "    FAISS,  # 埋め込みを保存し、類似検索するためのVectorStoreクラス\n",
    "    k=1  # 作成する例の数\n",
    ")\n",
    "\n",
    "# FewShotPromptTemplateの準備\n",
    "prompt_from_string_examples = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # ExampleSelector\n",
    "    example_prompt=example_prompt,  # 例のフォーマット\n",
    "    prefix=\"すべての入力の反意語を与えてください\",  # プレフィックス\n",
    "    suffix=\"入力: {adjective}\\n出力:\",  # サフィックス\n",
    "    input_variables=[\"adjective\"],  # 入力変数\n",
    "    example_separator=\"\\n\\n\"  # プレフィックス・例・サフィックスを結合する文字\n",
    "\n",
    ")\n",
    "print(prompt_from_string_examples.format(adjective=\"大きい\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.com/npaka/n/n886960b89de1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
