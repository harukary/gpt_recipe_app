{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = open('../open_ai.key','r').read()\n",
    "import os; os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.com/npaka/n/n61ad59380a43"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMの呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "「プログレッサム」(Progressam)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAIChat\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "# LLMの準備\n",
    "llm = OpenAIChat(temperature=0.9)\n",
    "# LLMの呼び出し\n",
    "print(llm(\"コンピュータゲームを作る新会社名の案を1つ出してください\"))\n",
    "\n",
    "# プロンプトテンプレートの準備\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"{product}を作る新会社名の案を1つ出してください\",\n",
    ")\n",
    "\n",
    "# LLMChainの準備\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# LLMChainの実行\n",
    "print(chain.run(\"家庭用ロボット\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m浜辺で夕暮れ時に出会った二人の男女が、互いに惹かれ合い恋に落ちる。しかし、男性は既婚者であり、女性は彼の妻と子供たちと別れて暮らしていたことが明らかになる。二人は運命に抗うことができず、その関係は続くが、やがて妻がそれを知り、男性は妻との関係を取り戻すことを決意する。女性は彼を止めることができず、絶望の中、浜辺で自殺を図る。男性は女性を救おうとするが、既に手遅れであった。浜辺は静かに夕暮れ時を迎え、悲劇的な結末に終わる。\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "この作品は、人間の愛と運命の複雑さを描いた感動的なドラマである。二人の恋の行方に注目しながら、物語は徐々にその深層に迫っていく。男性の葛藤や女性の孤独、そして妻の苦悩など、登場人物たちの心情描写が非常にリアルで、観客の共感を呼び起こす。\n",
      "\n",
      "特に、浜辺の美しい光景と寂しげな音楽が、物語の雰囲気を一層引き立てる。終盤の自殺シーンは、圧倒的な迫力があり、観客は涙を堪えきれなくなるだろう。しかしながら、登場人物たちの行為や決断に対して、観客は様々な感情を抱くことになるだろう。この作品は、愛とは何か、そして人生の意味について考えさせられる、深い内容を持っている。全ての演劇ファンにお勧めできる。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAIChat\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 1つ目のチェーンの準備 : 劇のタイトルからあらすじを生成\n",
    "# LLMの準備\n",
    "llm = OpenAIChat(temperature=.7)\n",
    "# テンプレートの準備\n",
    "template = \"\"\"あなたは劇作家です。劇のタイトルが与えられた場合、そのタイトルのあらすじを書くのがあなたの仕事です。\n",
    "\n",
    "タイトル:{title}\n",
    "あらすじ:\"\"\"\n",
    "# プロンプトテンプレートの準備\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"title\"], \n",
    "    template=template\n",
    ")\n",
    "# LLMChainの準備\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 2つ目のチェーン : 劇のあらすじからレビューを生成\n",
    "# LLMの準備準備\n",
    "llm = OpenAIChat(temperature=.7)\n",
    "# テンプレートの準備\n",
    "template = \"\"\"あなたは演劇評論家です。 劇のあらすじが与えられた場合、そのあらすじのレビューを書くのがあなたの仕事です。\n",
    "\n",
    "あらすじ:\n",
    "{synopsis}\n",
    "レビュー:\"\"\"\n",
    "# プロンプトテンプレートの準備\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"synopsis\"], \n",
    "    template=template\n",
    ")\n",
    "# LLMChainの準備\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "# SimpleSequentialChainで2つのチェーンを繋ぐ\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[synopsis_chain, review_chain], \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# SimpleSequentialChainの実行\n",
    "review = overall_chain.run(\"浜辺の夕暮れ時の悲劇\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.com/npaka/n/n2f89fb3bf91b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ拡張生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2614, which is longer than the specified 500\n",
      "Created a chunk of size 525, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "4\n",
      "人造人間・セル編\n",
      "ナメック星での闘いから約1年後、密かに生き延びていたフリーザとその一味が地球を襲撃するが、謎の超サイヤ人によって撃退される。トランクスと名乗るその青年は、自分は未来からやってきたブルマとベジータの息子であることを悟空にだけ明かすと同時に、悟空は心臓病によって命を落とすこと、3年後に現れる2体の人造人間が絶望の未来をもたらすことを告げる。その後本当に心臓病によって危篤状態になるも、トランクスから渡された特効薬によって生還、来るべき日に備えて3年間各々に修行してその日を迎える悟空たちであったが、事態はトランクスが知っている歴史とは大きく違うものとなり、彼さえ知らなかった人造人間たちまで現れ、さらに究極の人造人間・セルが未来から出現。悟空らの想定を遥かに超えた戦士が続々と現れた。\n"
     ]
    }
   ],
   "source": [
    "# パッケージのインポート\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "# テキストの読み込み\n",
    "with open(\"data/dragonball.txt\",\"r\") as f:\n",
    "    dragonball_txt = f.read()\n",
    "\n",
    "# テキストを小さなテキストに分割\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=0\n",
    ")\n",
    "texts = text_splitter.split_text(dragonball_txt)\n",
    "\n",
    "query = \"トランクスの両親は誰？\"\n",
    "\n",
    "# 関連するテキストの抽出\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "docs = docsearch.similarity_search(query)\n",
    "\n",
    "# 確認\n",
    "print(len(texts))\n",
    "print(len(docs))\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.com/npaka/n/n6b7a07e492f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エージェント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = open('../open_ai.key','r').read()\n",
    "serp_key = open('../serp.key','r').read()\n",
    "import os; os.environ[\"OPENAI_API_KEY\"] = openai_key; os.environ[\"SERPAPI_API_KEY\"] = serp_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI don't understand the question, I need to translate it to English.\n",
      "Action: Search\n",
      "Action Input: \"Translate '富士山の高さに2を掛けると？' to English\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTranslations in context of \"富士山\" in Japanese-English from Reverso Context: 富士山登山. ... 標高3776mの富士山の山頂で長らく気象観測が行われてきた。\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe question is asking what happens when you multiply the height of Mount Fuji by 2.\n",
      "Action: Calculator\n",
      "Action Input: 3776 x 2\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 7552\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 7552\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7552'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAIChat\n",
    "\n",
    "# LLMの準備準備\n",
    "llm = OpenAIChat(temperature=0)\n",
    "# ツールの準備\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "# エージェントの準備\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=\"zero-shot-react-description\", \n",
    "    verbose=True\n",
    ")\n",
    "# エージェントの実行\n",
    "agent.run(\"富士山の高さに2を掛けると？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI don't know the address of Tokyo Disneyland, so I need to look it up.\n",
      "Action: Search\n",
      "Action Input: \"Tokyo Disneyland address\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTokyo Disneyland (東京ディズニーランド, Tōkyō Dizunīrando) (local nickname TDL) is a 115-acre (47 ha) theme park at the Tokyo Disney Resort in Urayasu, Chiba Prefecture, Japan, near Tokyo. Its main gate is directly adjacent to both Maihama Station and Tokyo Disneyland Station.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the address of Tokyo Disneyland.\n",
      "Final Answer: The address of Tokyo Disneyland is in Urayasu, Chiba Prefecture, Japan, near Tokyo. Its main gate is directly adjacent to both Maihama Station and Tokyo Disneyland Station.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The address of Tokyo Disneyland is in Urayasu, Chiba Prefecture, Japan, near Tokyo. Its main gate is directly adjacent to both Maihama Station and Tokyo Disneyland Station.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# エージェントの実行\n",
    "agent.run(\"東京ディズニーランドの住所は？\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://note.com/npaka/n/n95e5bce0e1d6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メモリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = open('../open_ai.key','r').read()\n",
    "import os; os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: こんにちは！\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' こんにちは！私はAIです。どうぞよろしくお願いします！'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "# ConversationChainの準備\n",
    "conversation = ConversationChain(llm=OpenAI(temperature=0), verbose=True)\n",
    "\n",
    "# 会話の実行\n",
    "conversation.predict(input=\"こんにちは！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: こんにちは！\n",
      "AI:  こんにちは！私はAIです。どうぞよろしくお願いします！\n",
      "Human: AIさんはどこで生まれたのですか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 私はコンピューター上で生まれました。私はプログラムによって作られました。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会話の実行\n",
    "conversation.predict(input=\"AIさんはどこで生まれたのですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: こんにちは！\n",
      "AI:  こんにちは！私はAIです。どうぞよろしくお願いします！\n",
      "Human: AIさんはどこで生まれたのですか？\n",
      "AI:  私はコンピューター上で生まれました。私はプログラムによって作られました。\n",
      "Human: 何という名前のコンピュータですか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 私の名前はAIですが、コンピューターの名前はわかりません。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会話の実行\n",
    "conversation.predict(input=\"何という名前のコンピュータですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: こんにちは！\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' こんにちは！私はAIです。どうぞよろしくお願いします！'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "\n",
    "# ConversationChainの準備\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=OpenAI(temperature=0), \n",
    "    memory=ConversationSummaryMemory(llm=OpenAI()), \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 会話の実行\n",
    "conversation_with_summary.predict(input=\"こんにちは！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human and AI greet each other, the AI introducing itself as an AI and asking to be treated kindly.\n",
      "Human: AIさんはどこで生まれたのですか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 私は、コンピューター上で生まれました。私は、プログラムとデータを使用して作成されました。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会話の実行\n",
    "conversation_with_summary.predict(input=\"AIさんはどこで生まれたのですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human and AI greet each other, the AI introducing itself as an AI and asking to be treated kindly. The human then asked where the AI was born and the AI replied that it was born on a computer, created using programs and data.\n",
      "Human: 何という名前のコンピュータですか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 私の名前は、AI-01です。私は、プログラムとデータを使用して作成されたコンピュータ上で誕生しました。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会話の実行\n",
    "conversation_with_summary.predict(input=\"何という名前のコンピュータですか？\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
